{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob \n",
    "import random\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "# from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split, ConcatDataset\n",
    "import torchvision.transforms as tt\n",
    "from tqdm import tqdm_notebook\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(0)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataset class for mammography images\n",
    "class MammographyDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path= self.image_paths[idx]\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return img, label\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(<your_metadata.csv>)\n",
    "df = df[df['label']>0] # Including BI-RADS 1-5\n",
    "df['label'] = df['label']-1 # Rescoring to 0-4\n",
    "image_paths = df['name'].to_list()\n",
    "labels = df['label']\n",
    "labels = labels.to_list()\n",
    "print(image_paths)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, test_images, train_labels, test_labels = train_test_split(image_paths, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming image_paths and labels are already defined\n",
    "train_dataset = MammographyDataset(train_images, train_labels, transform=transform)\n",
    "test_dataset = MammographyDataset(test_images, test_labels, transform=transform)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetFC(nn.Module):\n",
    "    def __init__(self, num_classes=5):\n",
    "        super(ResNetFC, self).__init__()\n",
    "        self.base_model = models.resnet50(pretrained=True)\n",
    "        self.fc_in_features = self.base_model.fc.in_features\n",
    "        self.base_model.fc = nn.Identity() \n",
    "        self.fc1 = nn.Linear(self.fc_in_features, 100)\n",
    "        self.fc2 = nn.Linear(100, 50)\n",
    "        self.fc3 = nn.Linear(50, num_classes)\n",
    "\n",
    "    def forward(self, img):\n",
    "        feat = self.base_model(img)\n",
    "        output = self.fc1(feat)\n",
    "        output = self.fc2(output)\n",
    "        output = self.fc3(output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\");\n",
    "model = ResNetFC()\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters and other configs\n",
    "config = {\n",
    "    'architecture': 'feedforward',\n",
    "    'lr': 0.0001,\n",
    "    'scheduler_factor': 0.5,\n",
    "    'scheduler_patience': 2,\n",
    "    'scheduler_min_lr': 1e-6,\n",
    "    'epochs': 40\n",
    "}\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    'min',\n",
    "    factor=config['scheduler_factor'],\n",
    "    patience=config['scheduler_patience'],\n",
    "    min_lr=config['scheduler_min_lr']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "min_loss = 1000\n",
    "for epoch in tqdm_notebook(range(config['epochs'])):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{config['epochs']}], Train Loss: {running_loss / len(train_dataloader):.6f}, learning rate : {optimizer.param_groups[0]['lr']}\")\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "        scheduler.step(test_loss)\n",
    "        \n",
    "    print(f\"Test Loss: {test_loss / len(test_dataloader):.6f}\")\n",
    "        \n",
    "    if test_loss < min_loss:\n",
    "        state_dict = {\n",
    "            'epoch': epoch,\n",
    "            'model': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'scheduler': scheduler.state_dict(),\n",
    "            'train_loss': running_loss,\n",
    "            'val_loss': test_loss,\n",
    "            'best_val_loss': min_loss,\n",
    "        }\n",
    "        weight_path = f\"<your_dir>/resnet50_pretrained_withhiddenlayers_{epoch}.pth\"\n",
    "        torch.save(model.state_dict(), weight_path)\n",
    "        min_loss = test_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNetFC()\n",
    "weight_path = '<your_best_weight_path>'\n",
    "model.load_state_dict(torch.load(weight_path))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_loss = 0.0\n",
    "cm_labels = []\n",
    "cm_preds = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        cm_preds += list(preds.cpu().numpy())\n",
    "        cm_labels += list(labels.cpu().numpy())\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "print(f\"Test Loss: {test_loss / len(test_dataloader):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(tensor, mean, std):\n",
    "    for t, m, s in zip(tensor, mean, std):\n",
    "        t.mul_(s).add_(m)\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_plot(image_tensor, single_label):\n",
    "    input_tensor = image_tensor.unsqueeze(0).cuda()  # Add batch dimension if not already present\n",
    "    target_layers = [model.layer4[-1]] # Define the target layers and create the GradCAM object\n",
    "    cam = GradCAM(model=model, target_layers=target_layers)\n",
    "    targets = [ClassifierOutputTarget(single_label)] # Define the target class for Grad-CAM\n",
    "    grayscale_cam = cam(input_tensor=input_tensor, targets=targets)[0, :] # Generate the CAM\n",
    "    mean = [0.485, 0.456, 0.406]\n",
    "    std = [0.229, 0.224, 0.225]\n",
    "    denormalized_tensor = denormalize(image_tensor.clone(), mean, std)\n",
    "    rgb_img = denormalized_tensor.permute(1, 2, 0).cpu().numpy()  # Convert CHW to HWC format\n",
    "    rgb_img = (rgb_img * 255).astype(np.uint8)  # Scale to [0, 255] and convert to uint8 for visualization\n",
    "    visualization = show_cam_on_image(rgb_img / 255.0, grayscale_cam, use_rgb=True)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_tensor)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predicted_label = predicted.item()\n",
    "\n",
    "    plt.figure(figsize=(6, 3))\n",
    "\n",
    "    plt.subplot(1, 2, 1)  # 1 row, 2 columns, 1st subplot\n",
    "    plt.imshow(rgb_img, cmap='gray')\n",
    "    plt.title(f\"Original : BIRADS {single_label+1}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 2, 2)  # 1 row, 2 columns, 2nd subplot\n",
    "    plt.imshow(visualization)\n",
    "    plt.title(f\"Grad-CAM : BIRADS {predicted_label+1}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot up to 40 images, but feel free to adjust the number as needed.\n",
    "count = 0\n",
    "for img, label in test_dataset:\n",
    "    grad_plot(img, label)\n",
    "    count +=1\n",
    "    if count >=40:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the confusion matrix using seaborn\n",
    "cm = confusion_matrix(cm_labels, cm_preds)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=['1', '2', '3', '4', '5'],\n",
    "            yticklabels=['1', '2', '3', '4', '5'])\n",
    "\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# The input text\n",
    "text = \"\"\" Your model output, for example :\n",
    "Epoch [1/40], Train Loss: 1.367641, learning rate : 0.0001\n",
    "Test Loss: 1.330273\n",
    "Epoch [2/40], Train Loss: 0.992598, learning rate : 0.0001\n",
    "Test Loss: 1.575209\n",
    "Epoch [3/40], Train Loss: 0.595229, learning rate : 0.0001\n",
    "Test Loss: 1.421532\n",
    "\"\"\"\n",
    "\n",
    "# Regular expressions to extract epochs, train losses, and validation losses\n",
    "epoch_pattern = re.compile(r\"Epoch \\[(\\d+)/\\d+\\]\")\n",
    "train_loss_pattern = re.compile(r\"Train Loss: ([\\d\\.]+)\")\n",
    "val_loss_pattern = re.compile(r\"Test Loss: ([\\d\\.]+)\")\n",
    "\n",
    "# Extracting the data\n",
    "epochs = [int(epoch) for epoch in epoch_pattern.findall(text)]\n",
    "train_losses = [float(train_loss) for train_loss in train_loss_pattern.findall(text)]\n",
    "val_losses = [float(val_loss) for val_loss in val_loss_pattern.findall(text)]\n",
    "\n",
    "# Output the extracted data\n",
    "print(\"Epochs:\", epochs)\n",
    "print(\"Train Losses:\", train_losses)\n",
    "print(\"Validation Losses:\", val_losses)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_losses, label='Train Loss')\n",
    "plt.plot(epochs, val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Train and Validation Loss over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(all_preds, all_labels):\n",
    "    total_samples = len(all_labels)\n",
    "    correct_predictions = sum(1 for pred, label in zip(all_preds, all_labels) if pred == label)\n",
    "    accuracy = correct_predictions / total_samples\n",
    "    return accuracy\n",
    "\n",
    "accuracy = calculate_accuracy(cm_preds, cm_labels)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
